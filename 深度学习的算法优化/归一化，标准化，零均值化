参考链接：https://zhuanlan.zhihu.com/p/183591302
一. 归一化
【作用】将某个特征的值映射到[0,1]之间，消除量纲对最终结果的影响，使不同的特征具有可比性，使得原本可能分布相差较大的特征对模型有相同权重的影响，
提升模型的收敛速度，深度学习中数据归一化可以防止模型梯度爆炸。

二. 标准化
【作用】将原值减去均值后除以标准差，使得得到的特征满足均值为0，标准差为1的正态分布，使得原本可能分布相差较大的特征对模型有相同权重的影响。
举个例子，在KNN中，需要计算待分类点与所有实例点的距离。假设每个实例（instance）由n个features构成。如果选用的距离度量为欧式距离，数据预先没有经过归一化，
那些绝对值大的features在欧式距离计算的时候起了决定性作用。
从经验上说，标准化后，让不同维度之间的特征在数值上有一定比较性，得出的参数值的大小可以反应出不同特征对样本label的贡献度，可以大大提高分类器的准确性。

三. 零均值化
【作用】可以避免“Z型更新”的情况，这样可以加快神经网络的收敛速度。下面将分别以Sigmoid、tanh以及ReLu三个最为经典的激活函数来分别说明。

四. 正则化
简单来说，正则化是一种为了减小测试误差的行为(有时候会增加训练误差)。我们在构造机器学习模型时，最终目的是让模型在面对新数据的时候，可以有很好的表现。
当你用比较复杂的模型比如神经网络，去拟合数据时，很容易出现过拟合现象(训练集表现很好，测试集表现较差)，这会导致模型的泛化能力下降，这时候，我们就需要使用正则化，降低模型的复杂度。
参考链接：https://www.jianshu.com/p/569efedf6985


